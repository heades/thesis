\newcommand{\redtoby}[1]{\stackrel{ \ifrName{({\tiny #1})}}{\redto}}
\input{largedot}
\input{dtt-ott}
\input{L-ott}
\renewcommand{\dttdrulename}[1]{{\normalfont\scriptsize \text{#1}}}
\renewcommand{\Ldrulename}[1]{{\normalfont\scriptsize \text{#1}}}

\newcommand{\ndto}[1]{\to_{#1}}
\newcommand{\ndwedge}[1]{\wedge_{#1}}

\newcommand{\To}[0]{\Rightarrow}
\newcommand{\SN}[0]{\mathbf{SN}} 

Freedom of Speech and $\Sep$ are two very powerful programming
languages, but there is one feature they do not have, the ability to
reason about infinite data structures\index{Infinite Data Structures}
in an elegant way.  Infinite data can be defined and reasoned about
using corecursion and coinduction respectively\index{Coinduction}.
Now both of the previous languages contain induction, but only $\Sep$
contained inductive data types.  This chapter is about the design of a
new simply typed theory called Dualized Type Theory (DTT).

DTT is based on a new bi-intuitionistic logic
(BINT)\index{bi-intuitionistic Logic (BINT)} called Dualized
Intuitionistic Logic (DIL).  Bi-intuitionisim is a conservative
extension of intuitionistic logic with prefect duality.  That is, for
every logical connective of the logic its dual connective is also a
logical connective of the logic.  Due to the rich duality in BINT we
believe it shows promise of being a logical foundation for induction
and coinduction, because induction is dual to coinduction. Our working
hypothesis is that a logical foundation based on intuitionistic
duality will allow the semantic duality between induction and
coinduction to be expressed in type theory, yielding a solution to the
problems with these important features in existing systems.  For
example, Agda restricts how inductive and coinductive types can be
nested (see the discussion in \cite{abel+13}), while Coq supports
general mixed inductive and coinductive data, but in doing so,
sacrifices type preservation.

One particular difference in the design of DTT from Freedom of Speech
and $\Sep$ is that we started from a logic, and then derived a
corresponding type theory from it.  Thus, we make explicit use of the
computational trinity\index{Computational Trinity} (Chapter~\ref{chap:the_three_perspectives}) by
starting on the logical side, and then moving to the type theoretic
side.

Classical logic is rich with duality\index{Duality}.  Using the De Morgan dualities
it is straightforward to prove that conjunction is dual to disjunction
and negation is self dual.  In addition, it is also possible to prove
that $\lnot A \land B$ is dual to implication.  In intuitionistic
logic these dualities are no longer provable, but in
\cite{Rauszer:1974} Rauszer gives a conservative extension of the
Kripke semantics\index{Kripke Semantics} for intuitionistic logic that not only models
conjunction, disjunction, negation, and implication, but also the dual
to implication, by introducing a new logical connective. The usual
interpretation of implication in a Kripke model is as follows:
\begin{center}
  \begin{math}
    \interp{A \to B}_w = \forall w'.w \leq w' \to \interp{A}_{w'} \to \interp{B}_{w'}
  \end{math}
\end{center}
Now Rauszer took the dual of the previous interpretation to obtain the following:
\begin{center}
  \begin{math}
    \interp{A - B}_w = \exists w'.w' \leq w \land \lnot\interp{A}_{w'} \land \interp{B}_{w'}
  \end{math}
\end{center}
This is called subtraction or exclusion\index{Subtraction}.
Propositional BINT logic is a conservative extension of propositional
intuitionistic logic with perfect duality.  That is, it contains the
logical connectives for disjunction, conjunction, implication, and
subtraction, and it is sound and complete with respect to the
Rauszer's extended Kripke semantics.

BINT logic is fairly unknown in computer science.  Filinski studied a
fragment of BINT logic in his investigation into first class
continuations\index{Continuation} in \cite{Filinski:1989}.  Crolard
introduced a logic and corresponding type theory called subtractive
logic, and showed it can be used to study constructive coroutines in
\cite{crolard01,Crolard:2004}.  He initially defined subtractive logic
in sequent style with the Dragalin restriction, and then defined the
corresponding type theory in natural deduction style by imposing a
restriction on Parigot's $\lambda\mu$-calculus in the form of complex
dependency tracking.  Just as linear logicians have found -- for
example in \cite{Schellinx:1991} -- Pinto and Uustalu were able to
show that imposing the Dragalin restriction in subtractive logic
results in a failure of cut elimination \cite{Pinto:2009}.  They
recover cut elimination by proposing a new BINT logic called L that
lifts the Dragalin restriction by labeling formulas and sequents with
nodes and graphs respectively; this labeling corresponds to placing
constraints on the sequents where the graphs can be seen as abstract
Kripke models. Gor\'e et. al. also proposed a new BINT logic that
enjoys cut elimination using nested sequents; however it is currently
unclear how to define a type theory with nested sequents
\cite{DBLP:conf/aiml/GorePT08}.  Bilinear logic\index{Bilinear Logic} in its intuitionistic
form is a linear version of BINT and has been studied by Lambek in
\cite{Lambek:1993,Lambek:1995}.  Biasi and Aschieri propose a term
assignment to polarized bi-intuitionistic logic in
\cite{Biasi:2008:TAP:2365856.2365859}.  One can view the polarities of
their logic as an internalization of the polarities of the logic we
propose in this article. Bellin has studied BINT similar to that of
Biasi and Aschieri from a philosophical perspective in
\cite{Bellin:2004,Bellin:2005,Bellin:2014}, and he defined a linear
version of Crolard's subtractive logic for which he was able to
construct a categorical model using linear categories in
\cite{Bellin:2012}.

Throughout the remainder of this chapter we introduce the design of
DIL and its corresponding type theory DTT.  DIL is a single-sided
polarized formulation of Pinto and Uustalu's labeled sequent calculus
L.  DIL builds on L by removing the following rules (see
Section~\ref{sec:L} for a complete definition of L):
\begin{center}
  \begin{math}
    \begin{array}{lll}
      \Ldrulerefl{} & \Ldruletrans{}\\
      & \\
      \LdrulemonL{} & \LdrulemonR{}   
    \end{array}
  \end{math}
\end{center} 
We show in Chapter~\ref{chap:dualized_type_theory_anal} that in the
absence of the previous rules DIL still maintains
consistency\index{Consistency}
(Section~\ref{subsec:consistency_of_dil}) and completeness\index{Completeness}
(Section~\ref{sec:completeness}).  Furthermore, DIL is defined using a
dualized syntax which reduces the number of inference rules needed to
define the logic.  Again, DIL is a single-sided sequent calculus with
multiple conclusions and thus must provide a means of moving
conclusions from left to right. This is done in DIL using cuts on
hypotheses. We call these types of cuts ``axiom cuts.''

Now we consider BINT logic to be the closest extension of
intuitionistic logic to classical logic\index{Classical Logic} while maintaining
constructivity.  BINT has two forms of negation, one defined as usual,
$\lnot A \stackrel{\mathsf{def}}{=} A \to \perp$, and a second defined
interms of subtraction, $\mathop{\sim} A \stackrel{\mathsf{def}}{=}
\top - A$.  The latter we call ``non-$A$''.  Now in BINT it is
possible to prove $A \lor \mathop{\sim} A$ for any $A$
\cite{crolard01}. Furthermore, when the latter is treated as a type in
DTT, the inhabitant is a continuation\index{Continuation} without a canonical form,
because the inhabitant contains as a subexpression an axiom cut.
Thus, the presence of these continuations prevents the canonicity
result for a type theory -- like DTT -- from holding.  Thus, if
general cut elimination was a theorem of DIL, then $A \lor
\mathop{\sim} A$ would not be provable.  So DIL must contain cuts
that cannot be eliminated.  This implies that DIL does not enjoy
general cut elimination, but all cuts other than axiom cuts can be
eliminated. Throughout the sequel we define ``cut elimination'' as the
elimination of all cuts other than axiom cuts, and we call DIL ``cut
free'' with respect to this definition of cut elimination. The latter
point is similar to Wadler's dual calculus\index{Dual Calculus} \cite{Wadler:2005}.

\section{Pinto and Uustalu's L}
\label{sec:L}
In this section we briefly introduce Pinto and Uustalu's L from
\cite{Pinto:2009}.  The syntax for formulas, graphs, and contexts of L
are defined in Figure~\ref{fig:L-syntax}, while the inference rules
are defined in Figure~\ref{fig:L-ifr}.
\begin{figure} 
  \begin{center}
    \begin{math}
      \begin{array}{rrllllllllllllllllllll}
        (\text{formulas})   & <<A>>,<<B>>,<<C>> & ::= & <<True>>\,|\,<<False>>\,|\,<<A -> B>>\,|\,<<A - B>>\,|\,<<A /\ B>>\,|\,<<A \/ B>>\\
        (\text{graphs})     & <<Gr>> & ::= & <<.>>\,|\,<<(n,n')>> \,|\,<<Gr , Gr'>>\\
        (\text{contexts})   & <<G>> & ::= & <<.>>\,|\, <<n : A>> \,|\,<<G , G'>>\\
      \end{array}
    \end{math}
  \end{center}

  \caption{Syntax of L.}
  \label{fig:L-syntax}
\end{figure}
\begin{figure}
  \begin{mathpar}
    \Ldrulerefl{}   \and
    \Ldruletrans{}  \and
    \Ldrulehyp{}    \and
    \LdrulemonL{}   \and
    \LdrulemonR{}   \and
    \LdruletrueL{}  \and
    \LdruletrueR{}  \and
    \LdrulefalseL{} \and
    \LdrulefalseR{} \and
    \LdruleandL{}   \and
    \LdruleandR{}   \and
    \LdruledisjL{}  \and
    \LdruledisjR{}  \and
    \LdruleimpL{}   \and
    \LdruleimpR{}   \and
    \LdrulesubL{}   \and
    \LdrulesubR{}   
  \end{mathpar}
  
  \caption{Inference Rules for L.}
  \label{fig:L-ifr}
\end{figure} 
The formulas include true and false denoted $<<True>>$ and $<<False>>$
respectively, implication and subtraction denoted $<<A -> B>>$ and
$<<A - B>>$ respectively, and finally, conjunction and disjunction
denoted $<<A /\ B>>$ and $<<A \/ B>>$ respectively.  So we can see
that for every logical connective its dual is a logical connective of
the logic.  This is what we meant by BINT containing perfect
intuitionistic duality in the introduction. Sequents have the form
$<<G |- Gr n : A,D>>$, where $<<G>>$ and $<<D>>$ are multisets of
formulas labeled by a node, $<<Gr>>$ is the abstract Kripke model or
sometimes referred to as simply the graph of the sequent, and $<<n>>$
is a node in $<<Gr>>$.

Graphs are treated as sets of edges and we denote $<<(n1,n2)>> \in
<<Gr>>$ by $<<n1 Gr n2>>$.  Furthermore, we denote the union of two
graphs $<<Gr>>$ and $<<Gr'>>$ as $<<Gr U Gr'>>$. Now each formula
present in a sequent is labelled with a node in the graph.  This
labeling is denoted $<<n : A>>$ and should be read as the formula
$<<A>>$ is true at the node $<<n>>$.  We denote the operation of
constructing the list of nodes in a graph or context by $|<<Gr>>|$
and $|<<G>>|$ respectively. The reader should note that it is possible
for some nodes in the sequent to not appear in the graph.  For
example, the sequent $<<n : A |- . n : A,.>>$ is a derivable sequent.
Now the complete graph can always be recovered if needed by using the
graph structural rules $\Ldrulename{\normalsize refl}$, $\Ldrulename{\normalsize trans}$,
$\Ldrulename{\normalsize monL}$, and $\Ldrulename{\normalsize monR}$.

The labeling on formulas essentially adds constraints to the set of
Kripke models.  This is evident in the proof of consistency for DIL in
Section~\ref{subsec:consistency_of_dil}; see the definition of
validity. Consistency of L is stated in \cite{Pinto:2009} without a
detailed proof, but is proven complete with respect to Rauszer's
Kripke semantics using a counter model construction.  In
Section~\ref{sec:dualized_intuitionistic_logic_(dil)} we give a
translation of the formulas of L into the formulas of DIL, and in
Section~\ref{sec:completeness} we will give a translation of the rest
of L into DIL which will be used to conclude completeness of DIL.
% section L (end)

\section{Dualized Intuitionistic Logic}
\label{sec:dualized_intuitionistic_logic_(dil)}
The syntax for polarities, formulas, and graphs of DIL is defined in
Figure~\ref{fig:dil-syntax}, where $[[a]]$ ranges over atomic
formulas.  The following definition shows that DIL's formulas are
simply polarized versions of L's formulas.
\begin{definition}
  \label{def:L-form-to-DIL-form}
  The following defines a translation of formulas of L to formulas of
  DIL:
  \linespread{0.5}
  \begin{center}
    \small
    \begin{tabular}{cccccccccccccc}
      \begin{math}
      \begin{array}{lll}
        <<{True}>>   & = & [[<+>]]\\
        <<{False}>> & = & [[<->]]\\
      \end{array}
    \end{math}
      & \ \ \ \ \ \ 
      \begin{math}
      \begin{array}{lll}        
        <<{A /\ B}>> & = & [[{ A} /\+ {B }]]\\
        <<{A \/ B}>> & = & [[{ A} /\- {B }]]\\
      \end{array}
    \end{math}
      & \ \ \ \ \ \ 
      \begin{math}
      \begin{array}{lll}
        <<{A -> B}>> & = & [[{ A} ->+{ B }]]\\
        <<{B - A}>> & = & [[{ A} ->-{ B }]]\\
      \end{array}
    \end{math}
    \end{tabular}
  \end{center}
\end{definition}

We represent graphs as lists of edges denoted $[[n1 <=p n2]]$, where
we consider the edge $[[n1 <=+ n2]]$ to mean that there is a path from
$[[n1]]$ to $[[n2]]$, and the edge $[[n1 <=- n2]]$ to mean that there
is a path from $[[n2]]$ to $[[n1]]$.  Lastly, contexts denoted $[[G]]$
are represented as lists of formulas.
\begin{figure}[t]
  
  \begin{center}
    \begin{math}
      \begin{array}{rrllllllllllllllllllll}
        (\text{polarities}) & [[p]] & ::= & [[+]] \,|\, [[-]]\\
        (\text{formulas})   & [[A]],[[B]],[[C]] & ::= & [[a]]\,|\,[[< p >]]\,|\, [[A -> p B]]\,|\,[[A /\ p B]]\\
        (\text{graphs})     & [[Gr]] & ::= & [[.]] \,|\, [[n <= p n']] \,|\, [[Gr , Gr']]\\
        (\text{contexts})   & [[G]] & ::= & [[.]] \,|\, [[p A @ n]] \,|\, [[G , G']]\\
      \end{array}
    \end{math}
  \end{center}

  \caption{Syntax for DIL.}
  \label{fig:dil-syntax}
\end{figure}
\begin{figure}[t]
    \begin{mathpar}
        \dttdruleax{} \and
        \dttdruleunit{} \and
        \dttdruleand{} \and
        \dttdruleandBar{} \and
        \dttdruleimp{} \and
        \dttdruleimpBar{} \and        
        \dttdrulecut{} 
    \end{mathpar}
  
  \caption{Inference Rules for DIL.}
  \label{fig:dil-ifr}
\end{figure}
Throughout the sequel we denote the opposite of a polarity $[[p]]$ by
$[[bar p]]$.  This is defined by $[[bar +]] = [[-]]$ and $[[bar -]]
= +$.  The inference rules for DIL are in Figure~\ref{fig:dil-ifr}.

The sequent has the form $[[Gr ; G |- p A@n]]$ which when $[[p]]$ is
positive (resp. negative) can be read as the formula $[[A]]$ is true
(resp. false) at node $[[n]]$ in the context $[[G]]$ with respect to
the graph $[[Gr]]$.  The inference rules depend on a reachability
judgment that provides a means of proving when a node is reachable
from another within some graph $[[Gr]]$.  This judgment is defined in
Figure~\ref{fig:dil-reach}.
\begin{figure}
    \begin{mathpar}
      \dttdrulerelXXax{} \and
      \dttdrulerelXXrefl{} \and
      \dttdrulerelXXtrans{} \and
      \dttdrulerelXXflip{}
    \end{mathpar}
  
  \caption{Reachability Judgment for DIL.}
  \label{fig:dil-reach}
\end{figure}
In addition, the $\ifrName{\normalsize imp}$ rule depends on the operations 
$[[ | Gr | ]]$ and $[[| G |]]$ which simply compute the list of all 
the nodes in $[[Gr]]$ and $[[G]]$
respectively.  The condition $[[n' notin |Gr|,|G|]]$ in the
$\ifrName{\normalsize imp}$ rule is required for consistency.

The most interesting inference rules of DIL are the rules for
implication and coimplication from Figure~\ref{fig:dil-ifr}.  Let us
consider these two rules in detail. These rules mimic the definitions
of the interpretation of implication and coimplication in a Kripke
model.  The $\ifrName{\normalsize imp}$ rule states that the formula $[[p (A ->p
B)]]$ holds at node $[[n]]$ if assuming $[[p A@n']]$ for an arbitrary
node $[[n']]$ reachable from $[[n]]$, then $[[p B @ n']]$ holds.
Notice that when $[[p]]$ is positive $[[n']]$ will be a future node,
but when $[[p]]$ is negative $[[n']]$ will be a past node.  Thus,
universally quantifying over past and future worlds is modeled here by
adding edges to the graph.  Now the $\ifrName{\normalsize impBar}$ rule states the
formula $[[p (A ->bar p B)]]$ is derivable if there exists a node
$[[n']]$ that is provably reachable from $[[n]]$, $[[bar p A]]$ is
derivable at node $[[n']]$, and $[[p B @ n']]$ is derivable at node
$[[n']]$.  When $[[p]]$ is positive $[[n']]$ will be a past node, but
when $[[p]]$ is negative $[[n']]$ will be a future node. This is
exactly dual to implication. Thus, existence of past and future worlds
is modeled by the reachability judgment.

Before moving on to proving consistency and completeness of DIL we
first show that the formula $[[A /\- ~A]]$ has a proof in DIL that
contains a cut that cannot be eliminated.  This also serves as an
example of a derivation in DIL. Consider the following where we leave
off the reachability derivations for clarity and $[[G']] \equiv
[[G,h(-(A /\- ~A) @ n), h(-A@n)]]$:
\begin{center}  
  \scriptsize
  \begin{math}
      $$\mprset{flushleft}
      \inferrule* [right=\tiny \ifrName{andBar}] {
        $$\mprset{flushleft}
        \inferrule* [right=\tiny \ifrName{cut}] {
          $$\mprset{flushleft}
          \inferrule* [right=\tiny \ifrName{andBar}] {
            $$\mprset{flushleft}
            \inferrule* [right=\tiny \ifrName{impBar}] {
              $$\mprset{flushleft}
              \inferrule* [right=\tiny \ifrName{ax}] {
                \,
              }{[[Gr ; G' |- -A @ n]]}
              \\
              $$\mprset{flushleft}
              \inferrule* [right=\tiny \ifrName{unit}] {
                \,
              }{[[Gr ; G' |- +<+> @ n]]}
            }{[[Gr ; G' |- + ~A @ n]]}
          }{[[Gr ; G' |- +(A /\- ~A) @ n]]}
          \\
          $$\mprset{flushleft}
          \inferrule* [right=\tiny \ifrName{ax}] {
            \,
          }{[[Gr ; G' |- -(A /\- ~A) @ n]]}
        }{[[Gr ; G, -(A /\- ~A) @ n |- +A @ n]]}
      }{[[Gr ; G, -(A /\- ~A) @ n |- +(A /\- ~A) @ n]]}
  \end{math}
\end{center}
Now using only an axiom cut we may conclude the following derivation:
\begin{center}
  \scriptsize
  \begin{math}
    $$\mprset{flushleft}
    \inferrule* [right=\scriptsize \ifrName{cut}] {
      [[Gr ; G, -(A /\- ~A) @ n |- +(A /\- ~A) @ n]]
      \\
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize \ifrName{ax}] {
        \,
      }{[[Gr ; G, -(A /\- ~A) @ n |- -(A /\- ~A) @ n]]}
    }{[[Gr ; G |- +(A /\- ~A) @ n]]}
  \end{math}
\end{center}
The reader should take notice to the fact that all cuts within the
previous two derivations are axiom cuts, where the inner most cut uses
the hypothesis of the outer cut. Therefore, neither can be
eliminated.

\section{Dualized Type Theory }
\label{sec:dualized_type_theory}
In this section we give DIL a term assignment yielding Dualized Type
Theory (DTT).  First, we introduce DTT, and give several examples
illustrating how to program in DTT.  

The syntax for DIL is defined in Figure~\ref{fig:dtt-syntax}.
\begin{figure}[t]
  
  \begin{center}
    \begin{math}
      \begin{array}{crllllllllllllllllllll}
        (\text{indices})    & [[d]] & ::= & 1\,|\,2\\
        (\text{polarities}) & [[p]] & ::= & [[+]] \,|\, [[-]]\\
        (\text{types})      & [[A]],[[B]],[[C]] & ::= & [[< p >]]\,|\, [[A -> p B]]\,|\,[[A /\ p B]]\\
        (\text{terms})      & [[t]]  & ::= & 
                                 [[x]]\,|\,[[triv]]\,|\,[[(t,t')]]\,|\,[[inj d t]]\,|\,[[\x.t]]\,|\,[[<t,t'>]]\,|\,[[nu x.t*t']]\\
   (\text{canonical terms}) & [[c]] & ::= & [[x]] \mid [[triv]] \mid [[( t , t' )]] \mid [[inj d t]] \mid [[\x.t]] \mid [[<t,t'>]]\\
        (\text{graphs})     & [[Gr]] & ::= & [[.]] \,|\, [[n <= p n']] \,|\, [[Gr , Gr']]\\
        (\text{contexts})   & [[G]] & ::= & [[.]] \,|\, [[x : p A @ n]] \,|\, [[G , G']]\\
      \end{array}
    \end{math}
  \end{center}

  \caption{Syntax for DTT.}
  \label{fig:dtt-syntax}
\end{figure}
Polarities, types, and graphs are all the same as they were in DIL.
Contexts differ only by the addition of labeling each hypothesis with
a variable.  Terms, denoted $[[t]]$, consist of introduction
forms, together with cut terms $[[nu x . t * t']]$\footnote{In
  classical type theories the symbol $\mu$ usually denotes cut, but we
  have reserved that symbol -- indexed by a polarity -- to be used
  with inductive (positive polarity) and coinductive (negative
  polarity) types in future work.}.  We
denote variables as $[[x]]$, $[[y]]$, $[[z]]$, \ldots. The term
$[[triv]]$ is the introduction form for units, $[[(t, t')]]$ is the
introduction form for pairs, similarly the terms $[[inj 1 t]]$ and
$[[inj 2 t]]$ introduce disjunctions, $[[\x.t]]$ introduces
implication, and $[[<t,t'>]]$ introduces coimplication.  The
type-assignment rules are defined in Figure~\ref{fig:dtt-ifr}, and
result from a simple term assignment to the rules for DIL.
\begin{figure*}[t]
    \begin{mathpar}
      \dttdruleAx{}     \and
      \dttdruleUnit{}   \and
      \dttdruleAnd{}    \and
      \dttdruleAndBar{} \and
      \dttdruleImp{}    \and 
      \dttdruleImpBar{} \and
      \dttdruleCut{}    
    \end{mathpar}
  
  \caption{Type-Assignment Rules for DTT.}
  \label{fig:dtt-ifr}
\end{figure*}
Finally, the reduction rules for DTT are defined in
Figure~\ref{fig:dtt-red}.  
\begin{figure*}[t]
  \begin{mathpar}
    \dttdruleRImp{}        \and
    \dttdruleRImpBar{}     \and
    \dttdruleRAndOne{}     \and
    \dttdruleRAndTwo{}     \and
    \dttdruleRAndBarOne{}  \and
    \dttdruleRAndBarTwo{}  \and
    \dttdruleRRet{}        \and
    \dttdruleRBetaL{}      \and 
    \dttdruleRBetaR{}      
  \end{mathpar}
  
  \caption{Reduction Rules for DTT.}
  \label{fig:dtt-red}
\end{figure*}
The reduction rules should be considered rewrite rules that can be
applied anywhere within a term.  (The congruence rules for this
are omitted.) 

Programming in DTT is not functional programming as usual, so we now
give several illustrative examples.  The reader familiar with type
theories based on sequent calculi will find the following very
familiar. The encodings are very similar to that of Curien and
Herbelin's $\bar\lambda\mu\tilde\mu$-calculus\index{$\LBMMT$-Calculus}
\cite{Curien:2000}.  The locus of computation is the cut term, so
naturally, function application is modeled using cuts.  Suppose
\[
\begin{array}{lll}
D_1 & =^{\text{def}} & [[Gr ; H |- \x.t : + (A ->+ B)@n]]\\
D_2 & =^{\text{def}} & [[Gr ; H |- t' : +A@n]]\\
[[H']] & =^{\text{def}} & [[H, y : -B@n]]
\end{array}
\]
Then we can construct the following typing derivation:
\begin{center}
  \footnotesize
  \begin{math}
    $$\mprset{flushleft}
    \inferrule* [right=\tiny \ifrName{cut}] {
      D_1
      \\
      $$\mprset{flushleft}
      \inferrule* [right=\tiny \ifrName{impBar}] {
        D_2
        \\
        $$\mprset{flushleft}
        \inferrule* [right=\tiny \ifrName{ax}] {
          \,
        }{[[Gr ; H' |- y : -B@n]]}
      }{[[Gr ; H' |- <t' , y> : -(A->+B)@n]]}
    }{[[Gr ; H |- nu y.\x.t * <t' , y> : +B@n]]}
  \end{math}
\end{center}
Implication was indeed eliminated, yielding the conclusion.

There is some intution one can use while thinking of this style of
programming.  In \cite{kimura+09} Kimura and Tatsuta explain how we
can think of positive variables as input ports, and negative variables
as output ports. Clearly, these notions are dual.  Then a cut of the
form $[[nu z.t * t']]$ can be intuitively understood as a device
capable of routing information.  We think of this term as first
running the term $[[t]]$, and then plugging its value into the
continuation\index{Continuation} $[[t']]$.  Thus, negative terms are
continuations. Now consider the instance of the previous term 
$[[nu z.t * y]]$ where $[[t]]$ is a positive term and $[[y]]$ is a negative
variable (an output port).  This can be intuitively understood as
after running $[[t]]$, route its value through the output port $[[y]]$.
Now consider the instance $[[nu z.t * z]]$.  This term can be
understood as after running the term $[[t]]$, route its value through
the output part $[[z]]$, but then capture this value as the return
value.  Thus, the cut term reroutes output ports into the actual
return value of the cut.  
% AS: removed the text below, because this is not what is happening in 
% this case, but rather when we have nu x . t * y where y is different from
% x and not free in t -- but we did not try to handle such cases.
%
%We can also think of this instance as an
%exception, and this intuition fits nicely with the reduction rule
%$\ifrName{RRet}$ in Figure~\ref{fig:dtt-red}.  In that rule we simply
%throw away the outer context and reduce to $[[t]]$.  Furthermore,
%this instance can be seen as an axiom cut.

There is one additional bit of intuition we can use when thinking about
programming in DTT. We can think of cuts of the form 
\[ \nu z.(\lambda x_1\cdots\lambda x_i.t) \mathbin{\Cdot[2]} \langle t_1, \langle t_2, \cdots \langle t_i, z \rangle \cdots \rangle \]
as an abstract machine, where $\lambda x_1\cdots\lambda x_i.t$ is the 
functional part of the machine, and $\langle t_1, \langle t_2, \cdots \langle t_i, z \rangle \cdots \rangle$ is 
the stack of inputs the abstract machine will apply the function to
ultimately routing the final result of the application through
$[[z]]$, but rerouting this into the return value. 
This intuition is not new, but was first observed by Curien and
Herbelin in \cite{Curien:2000}; see also \cite{Curien:2002}.

Similarly to the eliminator for implication we can define the eliminator for disjunction in the form
of the usual case analysis\index{Case Constructs}. Suppose $[[Gr ; H |- t : + (A /\- B)@n]]$, $[[Gr ; H, x : + A@n |- t1 : + C@n]]$, and
$[[Gr ; H, x : + B@n |- t2 : + C@n]]$ are all admissible.  Then we can
derive the usual eliminator for disjunction.  Define 
\[ [[case t of x.t1 , x.t2]] \stackrel{\mathsf{def}}{=} [[nu z0 . (nu z1. (nu z2.t
* (z1,z2)) * (nu x.t2 * z0)) * (nu x.t1 * z0)]]. \]
Then we have the following result.
\begin{lemma}
  \label{lemma:disj-elim-adm}
  The following rule is admissible:
  \begin{center}
    \begin{math}
      $$\mprset{flushleft}
      \inferrule* [right=\ifrName{case}] {
        [[Gr ; H, x : p A@n |- t1 : p C@n]]
        \\\\
        [[Gr ; H, x : p B@n |- t2 : p C@n]]
        \\
        [[Gr ; H |- t : p (A /\bar p B)@n]]
      }{[[Gr; H |- case t of x.t1, x.t2 : p C @ n]]}
    \end{math}
  \end{center}
\end{lemma}
\begin{proof}
  Due to the size of the derivation in question we give several
  derivations which compose together to form the typing derivation of
  $[[Gr; H |- case t of x.t1, x.t2 : p C @ n]]$.  \ \\
  
  \noindent
  The typing derivation begins using cut as follows:

  \begin{math}
    $$\mprset{flushleft}
    \inferrule* [right=\ifrName{cut}] {
      D_0
      \\
      D_1
    }{[[Gr;H |- nu z0 . (nu z1. (nu z2.t * (z1,z2)) * (nu x.t2 * z0)) * (nu x.t1 * z0) : + C@n]]}
  \end{math} \\

  \noindent
  Then the remainder of the derivation depends on the following
  sub-derivations:

  \scriptsize
  \begin{math}
    \begin{array}{lcl}
      D_0:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{cut}] {
        D_3
        \\
        D_4
      }{[[Gr;H, z0 :- C @ n |- nu z1. (nu z2.t * (z1,z2)) * (nu x.t2 * z0) : + A@n]]}
    \end{array}
  \end{math} \\

  \begin{math}    
    \begin{array}{lcc}
      D_1: \\      
      &       
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{cut}] {
        D_2
        \\
        $$\mprset{flushleft}
        \inferrule* [right=\scriptsize\ifrName{ax}] {
          \,
        }{[[Gr;H, z0 :- C @ n, x : + A@n |- z0 : - C@n]]}               
      }{[[Gr;H, z0 :- C @ n |- nu x.t1 * z0 : - A@n]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcc}
      D_2: \\      
      & 
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{Weakening}] {
        [[Gr;H, x : + A@n |- t1 : + C@n]]
      }{[[Gr;H, z0 :- C @ n, x : + A@n |- t1 : + C@n]]}
    \end{array}
  \end{math} \\  

  \begin{math}
    \begin{array}{lcl}
      D_4:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{cut}] {
        D_5
        \\        
        [[Gr;H, z0 :- C @ n, z1 : - A @ n, x : + B@n |- z0 : - C@n]]
      }{[[Gr;H, z0 : - C @ n, z1 : - A @ n |- nu x.t2 * z0 : - B@n]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcl}
      D_3:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{cut}] {
        D_6
        \\
        D_7
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n |- nu z2.t * (z1,z2) : + B@n]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcl}
      D_5:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize\ifrName{Weakening}] {
        [[Gr;H, x : + B@n |- t2 : + C@n]]
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n, x : + B@n |- t2 : + C@n]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \scriptsize
    \begin{array}{lcl}
      D_6:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize \ifrName{Weakening}] {
        [[Gr;H |- t : + (A /\ - B)@n ]]
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n, z2 : - B @ n |- t : + (A /\ - B)@n ]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcl}
      D_7:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize \ifrName{and}] {
        D_8 
        \\
        D_9
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n, z2 : - B @ n |- (z1,z2) : - (A /\ - B)@n ]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcl}
      D_8:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize \ifrName{ax}] {
        \,
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n, z2 : - B @ n |- z1 : - A @n ]]}
    \end{array}
  \end{math} \\

  \begin{math}
    \begin{array}{lcl}
      D_9:\\
      &
      $$\mprset{flushleft}
      \inferrule* [right=\scriptsize \ifrName{ax}] {
        \,
      }{[[Gr;H, z0 :- C @ n, z1 : - A @ n, z2 : - B @ n |- z2 : - B @n ]]}
    \end{array}
  \end{math} \\
\end{proof}

Now consider the term $[[nu x . inj 1 (nu y. inj 2 <y,triv> * x) *
x]]$.  This term is the inhabitant of the type $[[A /\- ~A]]$, and its
typing derivation follows from the derivation given in
Section~\ref{sec:dualized_intuitionistic_logic_(dil)}.  We can see by
looking at the syntax that the cuts involved are indeed on the axiom
$[[x]]$, thus this term has no canonical form.  In \cite{Crolard:2004}
Crolard shows that inhabitants such as these amount to a constructive
coroutine\index{Coroutine}.  That is, it is a restricted form of a continuation.

We now consider several example reductions in DTT. In the following
examples we underline non-top-level redexes. The first example simply
$\alpha$-converts the function $[[\x.x]]$ into $[[\z.z]]$ as follows:
\begin{center}
  \begin{math}
    \begin{array}{lcl}    
      [[\z.u(nu y.\x.x * <z , y>)]] & \redtoby{RImp}   & [[\z.u(nu y.z *  y)]]\\
                                    & \redtoby{RRet}   & [[\z.z]]\\
    \end{array}
\end{math}
\end{center}
A more involved example is the application of the function
$[[\x.(\y.y)]]$ to the arguments $[[triv]]$ and $[[triv]]$. 
\begin{center}
  \begin{math}
    \begin{array}{lcl}
      [[nu z.\x.(\y.y) * <triv,<triv,z>>]] & \redtoby{RImp} & [[nu z.\y.y * <triv ,z>]]\\
      & \redtoby{RImp} & [[nu z.triv * z]]\\
      & \redtoby{RRet} & [[triv]]\\
    \end{array}
  \end{math}
\end{center}
% section dualized_type_theory_(dtt) (end)

%%% Local Variables: 
%%% mode: latex
%%% reftex-default-bibliography: ("/Users/hde/thesis/paper/thesis.bib")
%%% TeX-master: "/Users/hde/thesis/paper/thesis.tex"
%%% End: 